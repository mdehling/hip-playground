# HIP Playground
Malte Dehling <mdehling@gmail.com>

:rocm-install:      https://rocm.docs.amd.com/projects/install-on-linux/en/latest/index.html
:hipblas-install:   https://rocm.docs.amd.com/projects/hipBLAS/en/latest/install.html
:cuda-install:      https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html

This repository contains a few experiments in HIP kernel programming.

Building
--------
You will need a working {rocm-install}[ROCm installation] and either a ROCm
supported AMD graphics card or a CUDA capable NVIDIA graphics card.

In case you are using an AMD graphics card, you will also need to
{hipblas-install}[install hipBLAS].

On NVIDIA hardware, a working {cuda-install}[CUDA installation] is required.
Recent versions will come with cuBLAS included.

The included devcontainer/docker config will take care of the above steps for
you.  If you have access to the GitHub Codespaces GPU beta, you can simply
create a codespace for the `dev` configuration with an NVIDIA V100.

To build the experiments, simply run `make` and pass either `USE_HIPBLAS=1` or
`USE_CUBLAS=1`.

Running the Experiments
-----------------------
Simply run the generated executables and observe :)

[source,shell-session]
----
$ ./gemm
Generating random matrices A(m,k), B(k,n), C(m,n) on host...
(m = 4096, n = 4096, k = 4096)
alpha = 0.899897, beta = -1.31649
A = [ -0.826929 -0.840805 -2.05935 ... ]
B = [ -0.458748 1.45568 1.27641 ... ]
C = [ 1.15914 0.144615 -1.51211 ... ]
dt = 4453ms

Allocating device memory and copying vectors...
dt = 389ms

Performing SGEMM (blas on device)...
alpha*A*B + beta*C = [ -48.436 176.355 24.6866 ... ]
dt = 15ms

Performing SGEMM (device v1)...
alpha*A*B + beta*C = [ -48.436 176.355 24.6866 ... ]
max_sqerr = 9.53674e-07
dt = 2907ms

Performing SGEMM (device v2)...
alpha*A*B + beta*C = [ -48.436 176.355 24.6866 ... ]
max_sqerr = 1.23167e-07
dt = 31ms

Freeing device memory...
----
